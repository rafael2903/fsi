{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import ssl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model, Input\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from tensorflow.keras.backend import manual_variable_initialization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import itertools\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow import profiler\n",
    "from tensorflow import keras\n",
    "from keras_flops import get_flops\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "model = keras.models.load_model('model_file_path')\n",
    "\n",
    "# # Calculate FLOPs, may need to change batch size\n",
    "flops = get_flops(model, batch_size=32)\n",
    "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "model = tf.keras.models.load_model('model_file_path')\n",
    "\n",
    "t00=time.time()\n",
    "graph = tf.Graph()\n",
    "graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "\n",
    "t01=time.time()\n",
    "print(\"Iniialization time\",t01-t00)\n",
    "\n",
    "folder_path = os.path.abspath('images_file_path')\n",
    "images = []\n",
    "for img in os.listdir(folder_path):\n",
    "    cwd = os.getcwd()\n",
    "    files = os.listdir(cwd)\n",
    "    print(\"Files in %r: %s\" % (cwd, files))\n",
    "    img = image.load_img(img, color_mode='rgb', target_size=(224,224,3))\n",
    "    img = tf.keras.preprocessing.image.array_to_img(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255\n",
    "    # img = img.reshape((-1,) + img.shape)\n",
    "    images.append(img)\n",
    "images = np.vstack(images)\n",
    "# classes = classifier.predict(images, batch_size=32)\n",
    "\n",
    "print(img.dtype)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "t0=time.time()\n",
    "\n",
    "#Batch size has the model look at 32 images, so to get the average time for 1 image, divide the inference time by 32.\n",
    "y_pred = model.predict(images, batch_size=32)\n",
    "print(y_pred)\n",
    "classname = y_pred[0]\n",
    "print(\"Class: \",classname)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Inference time\", t1-t0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f05704f4740528ec32f28c6a01955d2cfab9eb44c7658f067771bac1ea3accf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
