{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nv9---D0Eb6-"
      },
      "outputs": [],
      "source": [
        "load_trained = True # Carrega o modelo salvo no último treinamento\n",
        "save_after_each_epoch = True # Salva o modelo a cada epoch concluída\n",
        "epochs = 1 # Quantidade de epochs do treinamento\n",
        "colab_enviroment = False # Se estiver rodando no colab, setar como True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import sklearn.metrics as metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "#Need to edit below import if using base model other than DenseNet\n",
        "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "#Need to edit below import if using base model other than DenseNet\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_path(path):\n",
        "    if colab_enviroment:\n",
        "        return \"/content/drive/MyDrive/FSI/\" + path\n",
        "    else:\n",
        "        return path\n",
        "\n",
        "if colab_enviroment:\n",
        "\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # unzip dataset\n",
        "    !unzip -q \"/content/drive/MyDrive/FSI/dataset/dataset.zip\" -d \"/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdjaS92snOC_",
        "outputId": "2bd5d04c-54fd-4f55-e1a8-d5f296d7d7c1"
      },
      "outputs": [],
      "source": [
        "#Setting seeds so that randomization is kept consistent.\n",
        "np.random.seed(70) \n",
        "random.seed(70) \n",
        "tf.random.set_seed(70)\n",
        "\n",
        "\n",
        "#This is the dimensions that each image will be shaped to\n",
        "#DenseNet201 requires 224 x 224.\n",
        "img_height, img_width = (224,224)\n",
        "#Batch size is the number of training examples utilized in one iteration. Could use 16, may increase compute time.\n",
        "batch_size = 32\n",
        "\n",
        "#These are the directories/folders where your images are stored for training, validation, and test datasets.\n",
        "train_data_dir = os.path.join(os.getcwd(), \"dataset/train\")\n",
        "valid_data_dir = os.path.join(os.getcwd(), \"dataset/test\")\n",
        "test_data_dir = os.path.join(os.getcwd(), \"dataset/val\")\n",
        "\n",
        "#ImageDataGenerator performs image augmentation for each image on the fly. Rotating, flipping, brightness, etc.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    width_shift_range= 0.2, # 0.2 fraction of total width/height\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"nearest\",\n",
        "    brightness_range=[0.9,1.1], #range for picking a shift value from\n",
        "    rotation_range =30, #degree range for random rotations\n",
        "    vertical_flip = True,\n",
        "    horizontal_flip = True,\n",
        "    validation_split = 0.05,\n",
        "    rescale=1./255) #rescaling image pixel values by the number of channels, 1/255\n",
        "\n",
        "#Pulls your training dataset images\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical' #more than 2 classes --> binary\n",
        "    ) #set as training data\n",
        "\n",
        "#Pulls your validation dataset images\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    valid_data_dir, #same directory as training data\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode= 'categorical') #set as validation data\n",
        "\n",
        "#Pulls your test dataset images. Note that you only want to use 1 image at a time for test.\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir, #same directory as training data\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size=1,\n",
        "    class_mode= 'categorical') #set as validation data\n",
        "\n",
        "\n",
        "if load_trained:\n",
        "  # load previous trained model\n",
        "  model = keras.models.load_model(make_path('saved_models/dense_1118.h5'))\n",
        "else:\n",
        "  #Loads array and classes of items in test folder for each batch\n",
        "  # x,y = test_generator.next()\n",
        "  # x.shape\n",
        "  # print(\"Xshape:\", x.shape)\n",
        "  # print(\"n_classes: \", valid_generator.num_classes)\n",
        "  # print(\"n_classes: \", test_generator.num_classes)\n",
        "  # print(\"y: \", y)\n",
        "\n",
        "  #Sets base model architecture, could swap out DenseNet201 for ResNet50, VGG16, etc\n",
        "  # Whether to include the fully-connected layer at top of network\n",
        "  # 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n",
        "  base_model = DenseNet201(include_top=False, weights='imagenet')\n",
        "  #Below x lines are the additional architecture attached beyond the base model\n",
        "  x = base_model.output\n",
        "  #Globalaveragepooling performs the 'flatten' purposes\n",
        "  # x = Flatten()(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  #128, 64 neuron fully-connected layers with relu activation\n",
        "  #Dropout for regularization\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  #Predicting a label for each image based on softmax activation, for 8 classes\n",
        "  predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  #Deciding whether to freeze the base model weights (imagenet) or allow them to update\n",
        "  #Setting this to 'True' implies we are training the entire model\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "  #Compile the model using stochastic gradient descent w/ learning rate and momentum values\n",
        "  #Use categorical crossentropy as the loss function\n",
        "  model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#CSV logger automatically keeps track of accuracy and loss for both training and validation during each epoch.\n",
        "#This is very convenient for graphing model performance through time later in R\n",
        "#Outputs a .csv file\n",
        "log_csv = CSVLogger('metrics.csv', separator=',', append = False)\n",
        "callbacks_list = [log_csv]\n",
        "\n",
        "if save_after_each_epoch:\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=make_path('saved_models/dense_1118.h5'),\n",
        "      save_weights_only=False,\n",
        "      verbose=1)\n",
        "\n",
        "  model_checkpoint_callback_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=make_path('saved_models/best_val_acc.h5'),\n",
        "      save_weights_only=False,\n",
        "      monitor='val_accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True,\n",
        "      initial_value_threshold=0.9,\n",
        "      verbose=1)\n",
        "  \n",
        "  callbacks_list.append(model_checkpoint_callback)\n",
        "  callbacks_list.append(model_checkpoint_callback_best)\n",
        "\n",
        "#Train the model for 100 epochs, verbose just tells you much info to display during training\n",
        "model.fit(train_generator, epochs = epochs, verbose=1, validation_data = valid_generator, callbacks=callbacks_list)\n",
        "\n",
        "#Save the model and weights\n",
        "#Mainly need the .h5 file to best hosted on the webapp\n",
        "model.save_weights(make_path('saved_models/dense_weights_1118'))\n",
        "model.save(make_path('saved_models/dense_1118.hdf5'))\n",
        "if not save_after_each_epoch:\n",
        "  model.save(make_path('saved_models/dense_1118.h5'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "f05704f4740528ec32f28c6a01955d2cfab9eb44c7658f067771bac1ea3accf5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
