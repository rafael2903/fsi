{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_trained = True # Carrega o modelo salvo no último treinamento\n",
    "save_after_each_epoch = True # Salva o modelo a cada epoch concluída\n",
    "epochs = 1 # Quantidade de epochs do treinamento\n",
    "colab_enviroment = False # Se estiver rodando no colab, setar como True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "#Need to edit below import if using base model other than DenseNet\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "#Need to edit below import if using base model other than DenseNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_enviroment:\n",
    "\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # unzip dataset\n",
    "    !unzip -q \"/content/drive/MyDrive/FSI/dataset/dataset.zip\" -d \"/dataset\"\n",
    "\n",
    "    if load_trained:\n",
    "        !cp -r /content/drive/MyDrive/FSI/saved_models /saved_models\n",
    "\n",
    "\n",
    "#Setting seeds so that randomization is kept consistent.\n",
    "np.random.seed(70) \n",
    "random.seed(70) \n",
    "tf.random.set_seed(70)\n",
    "\n",
    "\n",
    "#This is the dimensions that each image will be shaped to\n",
    "#DenseNet201 requires 224 x 224.\n",
    "img_height, img_width = (224,224)\n",
    "#Batch size is the number of training examples utilized in one iteration. Could use 16, may increase compute time.\n",
    "batch_size = 32\n",
    "\n",
    "#These are the directories/folders where your images are stored for training, validation, and test datasets.\n",
    "train_data_dir = r\"dataset/train\"\n",
    "valid_data_dir = r\"dataset/test\"\n",
    "test_data_dir = r\"dataset/val\"\n",
    "\n",
    "#ImageDataGenerator performs image augmentation for each image on the fly. Rotating, flipping, brightness, etc.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    width_shift_range= 0.2, # 0.2 fraction of total width/height\n",
    "    height_shift_range=0.2,\n",
    "    fill_mode=\"nearest\",\n",
    "    brightness_range=[0.9,1.1], #range for picking a shift value from\n",
    "    rotation_range =30, #degree range for random rotations\n",
    "    vertical_flip = True,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.05,\n",
    "    rescale=1./255) #rescaling image pixel values by the number of channels, 1/255\n",
    "\n",
    "#Pulls your training dataset images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical' #more than 2 classes --> binary\n",
    "    ) #set as training data\n",
    "\n",
    "#Pulls your validation dataset images\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    valid_data_dir, #same directory as training data\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode= 'categorical') #set as validation data\n",
    "\n",
    "#Pulls your test dataset images. Note that you only want to use 1 image at a time for test.\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    test_data_dir, #same directory as training data\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size=1,\n",
    "    class_mode= 'categorical') #set as validation data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('saved_models/best_val_acc.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the performance of the model using  generators\n",
    "val_loss, val_acc = model.evaluate(valid_generator, verbose=2)\n",
    "print('\\nValidation Accuracy:', val_acc)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The big block below lays out the steps for calculating and plotting\n",
    "# a classification report (precision, recall, etc.) and confusion matrix \n",
    "# I prefer to plot manually using wcipriano's pretty print confusion matrix\n",
    "\n",
    "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
    "Y_pred = model.predict(test_generator, steps= test_steps_per_epoch)\n",
    "true_classes = test_generator.classes\n",
    "predicted_classes = np.argmax(Y_pred, axis=1)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "cm1 = confusion_matrix(true_classes, predicted_classes)\n",
    "print(cm1)\n",
    "\n",
    "print('Classification Report')\n",
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "   \n",
    "    #This function prints and plots the confusion matrix.\n",
    "    #Normalization can be applied by setting `normalize=True`\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#Compute Confusion Matrix\n",
    "cnf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "cm_plot_labels = ['bacterial_blight', 'cercospora_leaf_blight','downey_mildew', 'frogeye', 'non_disease', 'potassium_deficiency', 'soybean_rust', 'target_spot']\n",
    "np.set_printoptions(precision=2)\n",
    "#Plot non-normalized cm\n",
    "plt.figure()\n",
    "ConfusionMatrixDisplay(cnf_matrix, classes=cm_plot_labels, title='Confusion Matrix, Without Normalization')\n",
    "plt.savefig(\"without_normalized.png\")\n",
    "\n",
    "#Plot normalized cm\n",
    "plt.figure()\n",
    "ConfusionMatrixDisplay(cnf_matrix, classes=cm_plot_labels, normalize=True, title='Normalized Confusion Matrix')\n",
    "plt.savefig(\"normalized.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f05704f4740528ec32f28c6a01955d2cfab9eb44c7658f067771bac1ea3accf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
