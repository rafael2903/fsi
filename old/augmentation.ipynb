{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'array_to_img' from 'keras.preprocessing.image' (C:\\Users\\rafae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\preprocessing\\image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m array_to_img, img_to_array, load_img\n\u001b[0;32m      6\u001b[0m \u001b[39m# Define the data generator\u001b[39;00m\n\u001b[0;32m      7\u001b[0m data_gen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      8\u001b[0m     rotation_range\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m,\n\u001b[0;32m      9\u001b[0m     width_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     fill_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'array_to_img' from 'keras.preprocessing.image' (C:\\Users\\rafae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\preprocessing\\image.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "# Define the data generator\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load all images in the directory\n",
    "data_dir = 'dataset/train/cercospera'\n",
    "files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "x_train = np.array([np.array(load_img(f)) for f in files])\n",
    "\n",
    "# Generate augmented data\n",
    "data_gen.fit(x_train)\n",
    "flow = data_gen.flow(x_train, batch_size=32)\n",
    "\n",
    "# Save the augmented images\n",
    "new_images_dir = 'new_images'\n",
    "if not os.path.exists(new_images_dir):\n",
    "    os.makedirs(new_images_dir)\n",
    "\n",
    "for i, batch in enumerate(flow):\n",
    "    for j in range(batch.shape[0]):\n",
    "        img = array_to_img(batch[j], scale=True)\n",
    "        img.save(os.path.join(new_images_dir, 'augmented_image_{}_{}.jpg'.format(i, j)))\n",
    "        if i * 32 + j >= x_train.shape[0]:\n",
    "            break\n",
    "    if i * 32 >= x_train.shape[0]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_img' from 'keras.preprocessing.image' (C:\\Users\\rafae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\preprocessing\\image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m save_img, img_to_array\n\u001b[0;32m      6\u001b[0m \u001b[39m# Define the data generator\u001b[39;00m\n\u001b[0;32m      7\u001b[0m data_gen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      8\u001b[0m     rotation_range\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m,\n\u001b[0;32m      9\u001b[0m     width_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     fill_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'save_img' from 'keras.preprocessing.image' (C:\\Users\\rafae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\preprocessing\\image.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import save_img, img_to_array\n",
    "\n",
    "# Define the data generator\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load all images in the directory\n",
    "data_dir = 'dataset/train/cercospera'\n",
    "files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "x_train = np.array([img_to_array(load_img(f)) for f in files])\n",
    "\n",
    "# Generate augmented data\n",
    "data_gen.fit(x_train)\n",
    "flow = data_gen.flow(x_train, batch_size=32)\n",
    "\n",
    "# Save the augmented images\n",
    "new_images_dir = 'new_images'\n",
    "if not os.path.exists(new_images_dir):\n",
    "    os.makedirs(new_images_dir)\n",
    "\n",
    "for i, batch in enumerate(flow):\n",
    "    for j in range(batch.shape[0]):\n",
    "        img = batch[j].astype('uint8')\n",
    "        save_img(os.path.join(new_images_dir, 'augmented_image_{}_{}.jpg'.format(i, j)), img)\n",
    "        if i * 32 + j >= x_train.shape[0]:\n",
    "            break\n",
    "    # if i * 32 >= x_train.shape[0]:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110 files belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m# print(class_name)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 47\u001b[0m save_image(image, class_name, filename)\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36msave_image\u001b[1;34m(image, path_dest, name)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_image\u001b[39m(image, path_dest, name):\n\u001b[0;32m     34\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m     image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(image, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m     image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mencode_jpeg(image, quality\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, optimize_size\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, chroma_downsampling\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mwrite_file(path_dest \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name, image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# from random import seed\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    batch_size=1,\n",
    "    image_size=(512, 512),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class_names = ds.class_names\n",
    "\n",
    "def augment(image, label):\n",
    "    seed = tf.random\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)\n",
    "    image = tf.image.random_contrast(image, lower=0.5, upper=1)\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1)\n",
    "    image = tf.image.random_hue(image, max_delta=0.1)\n",
    "    image = tf.image.random_crop(image, size=[1, 384, 384, 3])\n",
    "    image = tf.image.central_crop(image, central_fraction=0.75)\n",
    "    image = tf.image.rot90(image, k=1)\n",
    "    return image, label\n",
    "\n",
    "ds = ds.map(augment)\n",
    "# 256 + 128 = 384\n",
    "\n",
    "def save_image(image, path_dest, name):\n",
    "    image = image.numpy().astype(\"uint8\")\n",
    "    image = np.squeeze(image, axis=0)\n",
    "    image = tf.image.encode_jpeg(image, quality=100, optimize_size=True, chroma_downsampling=True)\n",
    "    tf.io.write_file(path_dest + \"/\" + name, image)\n",
    "\n",
    "i = 0\n",
    "# for i in range(ds.cardinality().numpy()):\n",
    "for image, label in ds:\n",
    "    i += 1\n",
    "    # image, label = next(iter(ds))\n",
    "    class_name = class_names[label.numpy().argmax()]\n",
    "    # print(class_name)\n",
    "    filename = f\"{i}.jpg\"\n",
    "    save_image(image, class_name, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(ds))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 files belonging to 1 classes.\n",
      "Found 64 files belonging to 1 classes.\n",
      "Found 64 files belonging to 1 classes.\n",
      "Found 64 files belonging to 1 classes.\n",
      "Found 64 files belonging to 1 classes.\n",
      "Found 64 files belonging to 1 classes.\n",
      "Found 64 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.rot90(image, k=1) if tf.random.uniform(()) > 0.5 else image\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=1.0)\n",
    "    image = tf.image.random_saturation(image, lower=0.75, upper=1.25)\n",
    "    image = tf.image.random_crop(image, size=[1, 448, 448, 3])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def save_image(image, path_dest, name):\n",
    "    image = image.numpy().astype(\"uint8\")\n",
    "    image = np.squeeze(image, axis=0)\n",
    "    image = tf.image.encode_jpeg(image, quality=100, optimize_size=False, chroma_downsampling=False)\n",
    "    tf.io.write_file(path_dest + \"/\" + name, image)\n",
    "\n",
    "\n",
    "for i in range(7):\n",
    "    ds = keras.preprocessing.image_dataset_from_directory(\n",
    "            \"images\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"categorical\",\n",
    "            class_names=None,\n",
    "            image_size=(512, 512),\n",
    "            shuffle=False,\n",
    "            batch_size=1,\n",
    "        )\n",
    "\n",
    "    class_names = ds.class_names\n",
    "\n",
    "    ds = ds.map(augment)\n",
    "\n",
    "    for j, (image, label) in enumerate(ds):\n",
    "        file_index  = (i * 64) + j\n",
    "        class_name = class_names[label.numpy().argmax()]\n",
    "        filename = f\"{file_index}.jpg\"\n",
    "        save_image(image, class_name, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.random' from 'C:\\\\Users\\\\rafae\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\random\\\\__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "seed = np.random.randint(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Caminho para o diretório com as imagens\n",
    "path = \"dataset/train/cercospera\"\n",
    "\n",
    "# Carregar as imagens\n",
    "images = [cv2.imread(os.path.join(path, f)) for f in os.listdir(path)]\n",
    "\n",
    "# Criar uma sequência de aumento de dados\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # flip horizontal com 50% de probabilidade\n",
    "    iaa.Affine(rotate=45), # rotacionar em 45 graus\n",
    "    iaa.Multiply((1.2, 1.5)) # aumentar o brilho com uma multiplicação aleatória entre 1.2 e 1.5\n",
    "])\n",
    "\n",
    "# Armazenar as imagens aumentadas em uma lista\n",
    "images_aug = []\n",
    "for i, image in enumerate(images):\n",
    "    image_aug = seq.augment_image(image)\n",
    "    images_aug.append(image_aug)\n",
    "    cv2.imwrite(\"image_aug_{0}.jpg\".format(i), image_aug)\n",
    "    print(\"Image{0}:\".format(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Caminho para o diretório com as imagens\n",
    "path = \"dataset/train/cercospera\"\n",
    "\n",
    "\n",
    "# Criar o diretório para salvar as imagens aumentadas, se ele ainda não existir\n",
    "if not os.path.exists(\"augmented_images\"):\n",
    "    os.makedirs(\"augmented_images\")\n",
    "\n",
    "# Criar um gerador de dados\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Carregar as imagens\n",
    "# images = [cv2.imread(os.path.join(path, f)) for f in os.listdir(path)]\n",
    "# Carregar as imagens\n",
    "images = [cv2.imread(os.path.join(path, f), cv2.IMREAD_COLOR) for f in os.listdir(path)]\n",
    "\n",
    "# Verificar se as imagens estão em formato RGB\n",
    "for image in images:\n",
    "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "        raise Exception(\"As imagens devem estar em formato RGB\")\n",
    "\n",
    "# Redimensionar as imagens para as dimensões especificadas\n",
    "img_height, img_width = 256, 256\n",
    "images = [cv2.resize(img, (img_height, img_width)) for img in images]\n",
    "\n",
    "# Normalizar as imagens para o intervalo [0,1]\n",
    "images = np.array(images, dtype=\"float32\") / 255.0\n",
    "\n",
    "# Gerar imagens aumentadas com base nas imagens originais\n",
    "i = 0\n",
    "for batch in datagen.flow(images, batch_size=1, save_to_dir='augmented_images', save_prefix='image', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i >= len(images):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data generator\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=keras.applications.resnet50.preprocess_input\n",
    ")\n",
    "\n",
    "# Load all images in the directory\n",
    "data_dir = 'dataset/train/cercospera'\n",
    "files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "x_train = np.array([np.expand_dims(keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(f, target_size=(224,224))), axis=0) for f in files])\n",
    "\n",
    "# Generate augmented data\n",
    "data_gen.fit(x_train)\n",
    "flow = data_gen.flow(x_train, batch_size=32, save_to_dir='new_images', save_prefix='augmented_image', save_format='jpg', seed=1)\n",
    "\n",
    "# Save the augmented images\n",
    "new_images_dir = 'new_images'\n",
    "if not os.path.exists(new_images_dir):\n",
    "    os.makedirs(new_images_dir)\n",
    "\n",
    "for i, batch in enumerate(flow):\n",
    "    for j in range(batch.shape[0]):\n",
    "        img = batch[j].astype('uint8')\n",
    "        if i * 32 + j >= x_train.shape[0]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Diretório com as pastas de classes\n",
    "images_dir = [\"dataset/test/cercospera\", \"dataset/test/soybean_rust\"]\n",
    "\n",
    "# Porcentagem de imagens para cada conjunto\n",
    "train_percentage = 0.6\n",
    "val_percentage = 0.2\n",
    "\n",
    "for image_dir in images_dir:\n",
    "  # Cria os diretórios para os conjuntos de dados\n",
    "  train_dir = os.path.join(image_dir, 'train32')\n",
    "  os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "  val_dir = os.path.join(image_dir, 'val32')\n",
    "  os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "  test_dir = os.path.join(image_dir, 'test32')\n",
    "  os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "  # Obtém a lista de todas as imagens no diretório de imagens\n",
    "  image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "  # Embaralha a lista de imagens\n",
    "  random.shuffle(image_files)\n",
    "\n",
    "  # Calcula o número de imagens para cada conjunto\n",
    "  train_count = int(train_percentage * len(image_files))\n",
    "  val_count = int(val_percentage * len(image_files))\n",
    "\n",
    "  # Copia as imagens para os diretórios correspondentes\n",
    "  for i, image_file in enumerate(image_files[:train_count]):\n",
    "      shutil.copy2(os.path.join(image_dir, image_file), os.path.join(train_dir, image_file))\n",
    "\n",
    "  for i, image_file in enumerate(image_files[train_count:train_count + val_count]):\n",
    "      shutil.copy2(os.path.join(image_dir, image_file), os.path.join(val_dir, image_file))\n",
    "\n",
    "  for i, image_file in enumerate(image_files[train_count + val_count:]):\n",
    "      shutil.copy2(os.path.join(image_dir, image_file), os.path.join(test_dir, image_file))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
