{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv9---D0Eb6-"
      },
      "outputs": [],
      "source": [
        "load_trained = True # Carrega do drive os dados do modelo salvo no último treinamento\n",
        "save_after_each_epoch = True # Salva o modelo a cada epoch concluída\n",
        "epochs = 1 # Quantidade de epochs do treinamento\n",
        "colab_enviroment = True # Se estiver rodando no colab, setar como True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjrfGe_oAw4H",
        "outputId": "7ee1a7ab-1f52-4ef0-ef17-23ef66889093"
      },
      "outputs": [],
      "source": [
        "if colab_enviroment:\n",
        "\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # unzip dataset\n",
        "    !unzip -q \"/content/drive/MyDrive/FSI/dataset/dataset.zip\" -d \"/dataset\"\n",
        "\n",
        "    if load_trained:\n",
        "        !cp -r /content/drive/MyDrive/FSI/saved_models /saved_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdjaS92snOC_",
        "outputId": "2bd5d04c-54fd-4f55-e1a8-d5f296d7d7c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 230 images belonging to 3 classes.\n",
            "Found 73 images belonging to 3 classes.\n",
            "Found 84 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import sklearn.metrics as metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "#Need to edit below import if using base model other than DenseNet\n",
        "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "#Need to edit below import if using base model other than DenseNet\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
        "\n",
        "#Setting seeds so that randomization is kept consistent.\n",
        "np.random.seed(70) \n",
        "random.seed(70) \n",
        "tf.random.set_seed(70)\n",
        "\n",
        "#CSV logger automatically keeps track of accuracy and loss for both training and validation during each epoch.\n",
        "#This is very convenient for graphing model performance through time later in R\n",
        "#Outputs a .csv file\n",
        "log_csv = CSVLogger('my_logs_robocrop.csv', separator=',', append = False)\n",
        "callbacks_list = [log_csv]\n",
        "\n",
        "#This is the dimensions that each image will be shaped to\n",
        "#DenseNet201 requires 224 x 224.\n",
        "img_height, img_width = (224,224)\n",
        "#Batch size is the number of training examples utilized in one iteration. Could use 16, may increase compute time.\n",
        "batch_size = 32\n",
        "\n",
        "#These are the directories/folders where your images are stored for training, validation, and test datasets.\n",
        "train_data_dir = r\"dataset/train\"\n",
        "valid_data_dir = r\"dataset/test\"\n",
        "test_data_dir = r\"dataset/val\"\n",
        "\n",
        "#ImageDataGenerator performs image augmentation for each image on the fly. Rotating, flipping, brightness, etc.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    width_shift_range= 0.2, # 0.2 fraction of total width/height\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"nearest\",\n",
        "    brightness_range=[0.9,1.1], #range for picking a shift value from\n",
        "    rotation_range =30, #degree range for random rotations\n",
        "    vertical_flip = True,\n",
        "    horizontal_flip = True,\n",
        "    validation_split = 0.05,\n",
        "    rescale=1./255) #rescaling image pixel values by the number of channels, 1/255\n",
        "\n",
        "#Pulls your training dataset images\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical' #more than 2 classes --> binary\n",
        "    ) #set as training data\n",
        "\n",
        "#Pulls your validation dataset images\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    valid_data_dir, #same directory as training data\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode= 'categorical') #set as validation data\n",
        "\n",
        "#Pulls your test dataset images. Note that you only want to use 1 image at a time for test.\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir, #same directory as training data\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size=1,\n",
        "    class_mode= 'categorical') #set as validation data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWJzJ75TVHNV"
      },
      "outputs": [],
      "source": [
        "if load_trained:\n",
        "  # load previous trained model\n",
        "  model = keras.models.load_model('saved_models/dense_1118.h5')\n",
        "else:\n",
        "  #Loads array and classes of items in test folder for each batch\n",
        "  # x,y = test_generator.next()\n",
        "  # x.shape\n",
        "  # print(\"Xshape:\", x.shape)\n",
        "  # print(\"n_classes: \", valid_generator.num_classes)\n",
        "  # print(\"n_classes: \", test_generator.num_classes)\n",
        "  # print(\"y: \", y)\n",
        "\n",
        "  #Sets base model architecture, could swap out DenseNet201 for ResNet50, VGG16, etc\n",
        "  # Whether to include the fully-connected layer at top of network\n",
        "  # 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n",
        "  base_model = DenseNet201(include_top=False, weights='imagenet')\n",
        "  #Below x lines are the additional architecture attached beyond the base model\n",
        "  x = base_model.output\n",
        "  #Globalaveragepooling performs the 'flatten' purposes\n",
        "  # x = Flatten()(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  #128, 64 neuron fully-connected layers with relu activation\n",
        "  #Dropout for regularization\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  #Predicting a label for each image based on softmax activation, for 8 classes\n",
        "  predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  #Deciding whether to freeze the base model weights (imagenet) or allow them to update\n",
        "  #Setting this to 'True' implies we are training the entire model\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "  #Compile the model using stochastic gradient descent w/ learning rate and momentum values\n",
        "  #Use categorical crossentropy as the loss function\n",
        "  model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "if save_after_each_epoch:\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath='saved_models/dense_1118.h5',\n",
        "      save_weights_only=False,\n",
        "      verbose=1)\n",
        "\n",
        "  model_checkpoint_callback_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath='saved_models/best_val_acc.h5',\n",
        "      save_weights_only=False,\n",
        "      monitor='val_accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True,\n",
        "      initial_value_threshold=0.9,\n",
        "      verbose=1)\n",
        "  \n",
        "  callbacks_list.append(model_checkpoint_callback)\n",
        "  callbacks_list.append(model_checkpoint_callback_best)\n",
        "\n",
        "#Train the model for 100 epochs, verbose just tells you much info to display during training\n",
        "model.fit(train_generator, epochs = epochs, verbose=1, validation_data = valid_generator, callbacks=callbacks_list)\n",
        "\n",
        "#Add the below block if you want to experiment with freezing the base weights for the above epochs.\n",
        "# Note, would need to change above to layer.trainable=False to freeze the above epochs.\n",
        "# Would likely change the learning rate above too.\n",
        "# And then unfreeze them for additional epochs below. (layer.trainable=True) \n",
        "\"\"\"\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator, epochs = 10, verbose=1, validation_data = valid_generator, callbacks=callbacks_list)\"\"\"\n",
        "\n",
        "#The big block below lays out the steps for calculating and plotting\n",
        "# a classification report (precision, recall, etc.) and confusion matrix \n",
        "# I prefer to plot manually using wcipriano's pretty print confusion matrix\n",
        "\n",
        "test_steps_per_epoch = np.math.ceil(valid_generator.samples / valid_generator.batch_size)\n",
        "Y_pred = model.predict(valid_generator, steps= test_steps_per_epoch)\n",
        "true_classes = valid_generator.classes\n",
        "predicted_classes = np.argmax(Y_pred, axis=1)\n",
        "class_labels = list(valid_generator.class_indices.keys())\n",
        "cm1 = confusion_matrix(true_classes, predicted_classes)\n",
        "print(cm1)\n",
        "\n",
        "print('Classification Report')\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "   \n",
        "    #This function prints and plots the confusion matrix.\n",
        "    #Normalization can be applied by setting `normalize=True`\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "#Compute Confusion Matrix\n",
        "cnf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "cm_plot_labels = ['bacterial_blight', 'cercospora_leaf_blight','downey_mildew', 'frogeye', 'non_disease', 'potassium_deficiency', 'soybean_rust', 'target_spot']\n",
        "np.set_printoptions(precision=2)\n",
        "#Plot non-normalized cm\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=cm_plot_labels, title='Confusion Matrix, Without Normalization')\n",
        "plt.savefig(\"without_normalized.png\")\n",
        "\n",
        "#Plot normalized cm\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=cm_plot_labels, normalize=True, title='Normalized Confusion Matrix')\n",
        "plt.savefig(\"normalized.png\")\n",
        "\n",
        "\n",
        "#Evaluate the performance of the model using test_generator\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
        "print('\\nTest Accuracy:', test_acc)\n",
        "\n",
        "#Save the model and weights\n",
        "#Mainly need the .h5 file to best hosted on the webapp\n",
        "model.save_weights('saved_models/dense_weights_1118')\n",
        "model.save('saved_models/dense_1118.hdf5')\n",
        "if not save_after_each_epoch:\n",
        "  model.save('saved_models/dense_1118.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhsrrqeRSBu1",
        "outputId": "f0cf9454-8a22-4599-a5fb-49d220da8f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84/84 [==============================] - 46s 476ms/step\n",
            "[[15  0 15]\n",
            " [ 7  0 14]\n",
            " [22  0 11]]\n",
            "84/84 - 45s - loss: 1.1042 - accuracy: 0.3333 - 45s/epoch - 540ms/step\n",
            "\n",
            "Test Accuracy: {'loss': 1.1042088270187378, 'accuracy': 0.3333333432674408}\n",
            "5/5 - 50s - loss: 1.0674 - accuracy: 0.4247 - 50s/epoch - 10s/step\n",
            "\n",
            "Validation Accuracy: {'loss': 1.0674052238464355, 'accuracy': 0.42465752363204956}\n"
          ]
        }
      ],
      "source": [
        " model = keras.models.load_model('/content/drive/MyDrive/saved_model/best_val_acc.h5')\n",
        "\n",
        "\n",
        "\n",
        " test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
        "Y_pred = model.predict(test_generator, steps= test_steps_per_epoch)\n",
        "true_classes = test_generator.classes\n",
        "predicted_classes = np.argmax(Y_pred, axis=1)\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "cm1 = confusion_matrix(true_classes, predicted_classes)\n",
        "print(cm1)\n",
        "\n",
        "# print('Classification Report')\n",
        "# report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "# print(report)\n",
        "\n",
        "# def plot_confusion_matrix(cm, classes,\n",
        "#                         normalize=False,\n",
        "#                         title='Confusion matrix',\n",
        "#                         cmap=plt.cm.Blues):\n",
        "   \n",
        "#     #This function prints and plots the confusion matrix.\n",
        "#     #Normalization can be applied by setting `normalize=True`\n",
        "    \n",
        "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "#     plt.title(title)\n",
        "#     plt.colorbar()\n",
        "#     tick_marks = np.arange(len(classes))\n",
        "#     plt.xticks(tick_marks, classes, rotation=45)\n",
        "#     plt.yticks(tick_marks, classes)\n",
        "\n",
        "#     if normalize:\n",
        "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#         print(\"Normalized confusion matrix\")\n",
        "#     else:\n",
        "#         print('Confusion matrix, without normalization')\n",
        "\n",
        "#     print(cm)\n",
        "\n",
        "#     thresh = cm.max() / 2.\n",
        "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "#         plt.text(j, i, cm[i, j],\n",
        "#             horizontalalignment=\"center\",\n",
        "#             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.ylabel('True label')\n",
        "#     plt.xlabel('Predicted label')\n",
        "\n",
        "# #Compute Confusion Matrix\n",
        "# cnf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "# cm_plot_labels = ['bacterial_blight', 'cercospora_leaf_blight','downey_mildew', 'frogeye', 'non_disease', 'potassium_deficiency', 'soybean_rust', 'target_spot']\n",
        "# np.set_printoptions(precision=2)\n",
        "# #Plot non-normalized cm\n",
        "# plt.figure()\n",
        "# plot_confusion_matrix(cnf_matrix, classes=cm_plot_labels, title='Confusion Matrix, Without Normalization')\n",
        "# plt.savefig(\"without_normalized.png\")\n",
        "\n",
        "# #Plot normalized cm\n",
        "# plt.figure()\n",
        "# plot_confusion_matrix(cnf_matrix, classes=cm_plot_labels, normalize=True, title='Normalized Confusion Matrix')\n",
        "# plt.savefig(\"normalized.png\")\n",
        "\n",
        "\n",
        "#Evaluate the performance of the model using test_generator\n",
        "test_metrics = model.evaluate(test_generator, verbose=2, return_dict=True)\n",
        "print('\\nTest Accuracy:', test_metrics)\n",
        "\n",
        "val_metrics = model.evaluate(valid_generator, verbose=2, return_dict=True)\n",
        "print('\\nValidation Accuracy:', val_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4rpx-GG1sxM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import ssl\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model, Input\n",
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "from tensorflow.keras.backend import manual_variable_initialization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "import itertools\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow import profiler\n",
        "from tensorflow import keras\n",
        "from keras_flops import get_flops\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "model = keras.models.load_model('model_file_path')\n",
        "\n",
        "# # Calculate FLOPs, may need to change batch size\n",
        "flops = get_flops(model, batch_size=32)\n",
        "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
        "\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "from PIL import Image\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "\n",
        "model = tf.keras.models.load_model('model_file_path')\n",
        "\n",
        "t00=time.time()\n",
        "graph = tf.Graph()\n",
        "graph_def = tf.compat.v1.GraphDef()\n",
        "\n",
        "with graph.as_default():\n",
        "    tf.import_graph_def(graph_def)\n",
        "\n",
        "\n",
        "t01=time.time()\n",
        "print(\"Iniialization time\",t01-t00)\n",
        "\n",
        "folder_path = os.path.abspath('images_file_path')\n",
        "images = []\n",
        "for img in os.listdir(folder_path):\n",
        "    cwd = os.getcwd()\n",
        "    files = os.listdir(cwd)\n",
        "    print(\"Files in %r: %s\" % (cwd, files))\n",
        "    img = image.load_img(img, color_mode='rgb', target_size=(224,224,3))\n",
        "    img = tf.keras.preprocessing.image.array_to_img(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    # img = img.reshape((-1,) + img.shape)\n",
        "    images.append(img)\n",
        "images = np.vstack(images)\n",
        "# classes = classifier.predict(images, batch_size=32)\n",
        "\n",
        "print(img.dtype)\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "t0=time.time()\n",
        "\n",
        "#Batch size has the model look at 32 images, so to get the average time for 1 image, divide the inference time by 32.\n",
        "y_pred = model.predict(images, batch_size=32)\n",
        "print(y_pred)\n",
        "classname = y_pred[0]\n",
        "print(\"Class: \",classname)\n",
        "\n",
        "t1 = time.time()\n",
        "print(\"Inference time\", t1-t0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXGbWkKyoKie"
      },
      "outputs": [],
      "source": [
        "# upload saved model to google drive\n",
        "# import shutil\n",
        "# shutil.copy('saved_model/dense_1118.h5',\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSaH-XBz9jJE"
      },
      "outputs": [],
      "source": [
        "# %mkdir saved_model\n",
        "# download saved model to \n",
        "# %cp /content/drive/MyDrive/dense_1118.hdf5 /content/saved_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9njHkXaM-adX",
        "outputId": "f8f72d29-b2e5-40d2-fe55-e34845274384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 230 images belonging to 3 classes.\n",
            "Found 73 images belonging to 3 classes.\n",
            "Found 84 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import sklearn.metrics as metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
        "\n",
        "#Setting seeds so that randomization is kept consistent.\n",
        "np.random.seed(70) \n",
        "random.seed(70) \n",
        "tf.random.set_seed(70)\n",
        "\n",
        "log_csv = CSVLogger('my_logs_robocrop.csv', separator=',', append = False)\n",
        "callbacks_list = [log_csv]\n",
        "\n",
        "img_height, img_width = (224,224)\n",
        "batch_size = 32\n",
        "\n",
        "train_data_dir = r\"full_images_2021/train_full\"\n",
        "valid_data_dir = r\"full_images_2021/test_full\"\n",
        "test_data_dir = r\"full_images_2021/validation_full\"\n",
        "\n",
        "# A linha \"preprocessing_function=preprocess_input\" significa que uma\n",
        "# função de pré-processamento será aplicada aos dados de entrada antes de \n",
        "#serem alimentados no modelo. O argumento \"preprocess_input\" é uma função\n",
        "# pré-definida da biblioteca Keras (ou do seu provedor, como o TensorFlow) que \n",
        "#aplica algumas operações de pré-processamento comuns em imagens, como normalização\n",
        "# de pixels, para melhorar o desempenho do modelo de aprendizado de máquina.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    # preprocessing_function=preprocess_input,\n",
        "    width_shift_range= 0.2, \n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"nearest\",\n",
        "    brightness_range=[0.9,1.1], \n",
        "    rotation_range =30, \n",
        "    vertical_flip = True,\n",
        "    horizontal_flip = True,\n",
        "    validation_split = 0.05,\n",
        "    rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical'\n",
        "    ) \n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    valid_data_dir, \n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode= 'categorical',\n",
        "    ) \n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir, \n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size=1,\n",
        "    class_mode= 'categorical'\n",
        ")\n",
        "    # shuffle=False) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNcLaIB0B0Ts",
        "outputId": "5adc8cf3-4327-498c-cc23-a6283ad2a7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84/84 [==============================] - 49s 528ms/step\n",
            "Confusion Matrix:\n",
            " [[ 9 10 11]\n",
            " [ 5  7  9]\n",
            " [16  3 14]]\n",
            "84/84 - 43s - loss: 0.1878 - accuracy: 0.9286 - 43s/epoch - 516ms/step\n",
            "\n",
            "Test Accuracy: 0.9286\n",
            "3/3 - 50s - loss: 0.1604 - accuracy: 0.9589 - 50s/epoch - 17s/step\n",
            "\n",
            "Validation Accuracy: 0.9589\n"
          ]
        }
      ],
      "source": [
        "model_path = '/content/drive/MyDrive/saved_model/best_val_acc.h5'\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "test_steps = len(test_generator)\n",
        "Y_pred = model.predict(test_generator, steps= test_steps)\n",
        "true_classes = test_generator.classes\n",
        "predicted_classes = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, verbose=2)\n",
        "print(\"\\nTest Accuracy: {:.4f}\".format(test_accuracy))\n",
        "\n",
        "val_loss, val_accuracy = model.evaluate(valid_generator, verbose=2)\n",
        "print(\"\\nValidation Accuracy: {:.4f}\".format(val_accuracy))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
